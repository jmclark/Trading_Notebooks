{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting\n",
    "______________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]\n",
      "pandas: 0.25.1\n",
      "numpy: 1.16.5\n",
      "pandas_datareader: 0.8.1\n",
      "requests: 2.22.0\n",
      "bs4: 4.8.0\n"
     ]
    }
   ],
   "source": [
    "# Package Importation\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas_datareader as pdr\n",
    "from datetime import date, timedelta\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import pickle\n",
    "from os import listdir\n",
    "import quandl\n",
    "\n",
    "'''\n",
    "# Input functions from other notebook\n",
    "import import_ipynb\n",
    "from functions_1 import *\n",
    "'''\n",
    "\n",
    "# Check versions\n",
    "print('python: {}'.format(sys.version))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('pandas_datareader: {}'.format(pdr.__version__))\n",
    "print('requests: {}'.format(requests.__version__))\n",
    "print('bs4: {}'.format(bs.__version__))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Quandl API Configuration\n",
    "quandl.ApiConfig.api_key = 'Q2-ookr-KYUHAPn8aAzL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Import Ticker and S&P 500 Price/ Volume Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Tickers\n",
    "def sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker.rstrip('\\n'))\n",
    "        \n",
    "    with open(\"Forecasting_Exp_1_Data\\sp500_tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "        \n",
    "    return tickers\n",
    "\n",
    "def sp500_yahoo(tickers, start, end):\n",
    "    yahoo_df = pd.DataFrame()\n",
    "    date_string = '_from_' + str(start) + '_to_' + str(end)\n",
    "\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        print(\"Collecting Yahoo data \", str(i+1), \" of \", str(len(tickers)), \": \", ticker)\n",
    "        try:\n",
    "            ticker_data = pdr.get_data_yahoo(symbols=ticker, start=start, end=end)\n",
    "            ticker_data['Ticker'] = ticker\n",
    "            yahoo_df = yahoo_df.append(ticker_data)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception\")\n",
    "            continue\n",
    "            \n",
    "    pickle_save_path = 'Forecasting_Exp_1_Data\\sp500_yahoo' + date_string + '.pickle'\n",
    "    with open(pickle_save_path,\"wb\") as f:\n",
    "        pickle.dump(yahoo_df,f)\n",
    "        \n",
    "    excel_save_path = 'Forecasting_Exp_1_Data\\sp500_yahoo' + date_string + '.xlsx'\n",
    "    yahoo_df.to_excel(excel_save_path)\n",
    "\n",
    "    return yahoo_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Functions to Import Quandl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(start, end):\n",
    "    date_string = '_from_' + str(start) + '_to_' + str(end)\n",
    "\n",
    "    sent_df = pd.DataFrame(quandl.get('AAII/AAII_SENTIMENT', start_date=start, end_date=end))\n",
    "    \n",
    "    pickle_save_path = 'Forecasting_Exp_1_Data\\sentiment' + date_string + '.pickle'\n",
    "    with open(pickle_save_path,\"wb\") as f:\n",
    "        pickle.dump(sent_df,f)\n",
    "        \n",
    "    excel_save_path = 'Forecasting_Exp_1_Data\\sentiment' + date_string + '.xlsx'\n",
    "    sent_df.to_excel(excel_save_path)\n",
    "    return quandl.get('AAII/AAII_SENTIMENT', start_date=start, end_date=end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Update Data Dictionary (Local Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update local datasets\n",
    "def update_data(start, end, overwrite_all = 0):\n",
    "    '''\n",
    "    Input: Dictionary of All Datasets\n",
    "    Returns: Updated Data, or saved data\n",
    "    '''\n",
    "    date_string = '_from_' + str(start) + '_to_' + str(end)\n",
    "\n",
    "    stored_files = listdir('Forecasting_Exp_1_Data')\n",
    "    print(\"Stored files: \", stored_files)\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    # Add sp500 tickers\n",
    "    if ('sp500_tickers.pickle' in stored_files) and (overwrite_all == 0):\n",
    "        print('Loading Tickers from file')\n",
    "        with open('Forecasting_Exp_1_Data\\sp500_tickers.pickle', 'rb') as f:\n",
    "            data_dict['sp500_tickers'] = pickle.load(f)\n",
    "    else:\n",
    "        print('Pulling Tickers from web')\n",
    "        data_dict['sp500_tickers'] = sp500_tickers()\n",
    "\n",
    "    # Add yahoo data\n",
    "    pickle_yahoo_path = \"sp500_yahoo\" + date_string + \".pickle\"\n",
    "    pickle_yahoo_dir_path = \"Forecasting_Exp_1_Data\\sp500_yahoo\" + date_string + \".pickle\"\n",
    "    if (pickle_yahoo_path in stored_files) and (overwrite_all == 0):\n",
    "        print('Loading Yahoo price data from file')\n",
    "        with open(pickle_yahoo_dir_path, 'rb') as f:\n",
    "            data_dict['sp500_yahoo'] = pickle.load(f)\n",
    "    else:\n",
    "        print('Pulling Yahoo price data from web')\n",
    "        data_dict['sp500_yahoo'] = sp500_yahoo(data_dict['sp500_tickers'], start, end)\n",
    "    \n",
    "    # Add sentiment Data\n",
    "    pickle_sent_path = \"sentiment\" + date_string + \".pickle\"\n",
    "    pickle_sent_dir_path = \"Forecasting_Exp_1_Data\\sentiment\" + date_string + \".pickle\"\n",
    "    if (pickle_sent_path in stored_files) and (overwrite_all == 0):\n",
    "        print('Loading sentiment data from file')\n",
    "        with open(pickle_sent_dir_path, 'rb') as f:\n",
    "            data_dict['sentiment'] = pickle.load(f)\n",
    "    else:\n",
    "        print('Pulling sentiment data from web')\n",
    "        data_dict['sentiment'] = get_sentiment(start, end)\n",
    "        \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data from  2018-12-14  to  2019-12-14\n",
      "Stored files:  ['sentiment_from_2018-12-14_to_2019-12-14.pickle', 'sentiment_from_2018-12-14_to_2019-12-14.xlsx', 'sp500_tickers.pickle', 'sp500_yahoo_from_2018-12-14_to_2019-12-14.pickle', 'sp500_yahoo_from_2018-12-14_to_2019-12-14.xlsx']\n",
      "Loading Tickers from file\n",
      "Loading Yahoo data from file\n",
      "Loading sentiment data from file\n"
     ]
    }
   ],
   "source": [
    "# Date information\n",
    "today = date.today()\n",
    "year_ago = today - timedelta(days=365)\n",
    "\n",
    "# Pull Stock Data\n",
    "print(\"Pulling data from \", year_ago, \" to \", today)\n",
    "\n",
    "data_dict = update_data(start=year_ago, end=today, overwrite_all = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
